{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgb.linkproppred.dataset_pyg import PyGLinkPropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tgbl-flight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PyGLinkPropPredDataset(name=name, root=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = dataset.get_TemporalData()\n",
    "data.t.shape\n",
    "np.unique(data.t).shape, data.t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PyGLinkPropPredDataset(name=name, root=\"datasets\")\n",
    "train_mask = dataset.train_mask\n",
    "val_mask = dataset.val_mask\n",
    "test_mask = dataset.test_mask\n",
    "data = dataset.get_TemporalData()\n",
    "\n",
    "train_data = data[train_mask]\n",
    "val_data = data[val_mask]\n",
    "test_data = data[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.eval_metric\n",
    "test_ns = dataset.load_test_ns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_TemporalData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.min(train_data.t), torch.max(train_data.t), \\\n",
    "    torch.min(val_data.t), torch.max(val_data.t), \\\n",
    "    torch.min(test_data.t), torch.max(test_data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StarDataset import StarDataset\n",
    "\n",
    "summary_writer = 'TGN_new_wout_fish'\n",
    "csv_name = 'tgn_wout_fish'\n",
    "event_path = '/data/mala711/GNNthesis/data/Starboard/events.parquet'\n",
    "data_path = '/data/mala711/GNNthesis/data/Starboard/vessels.csv'\n",
    "batch_size = 5000\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "memory_dim = time_dim = embedding_dim = 100\n",
    "epochs = 20\n",
    "lr = 0.0001\n",
    "l1_reg = 0\n",
    "verbose = True\n",
    "self_loop = False\n",
    "with_fish = False\n",
    "date_range = 'all'\n",
    "\n",
    "sb_data = StarDataset(event_path, data_path, date_range, with_fish, self_loop)\n",
    "\n",
    "data = sb_data.get_data()\n",
    "ind_map = sb_data.get_ind_map()\n",
    "rev_ind_map = sb_data.get_rev_ind_map()\n",
    "rev_event_dict = sb_data.get_rev_event_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "train_data, val_data, test_data = data.train_val_test_split(\n",
    "    val_ratio=val_ratio, test_ratio=val_ratio)\n",
    "\n",
    "torch.min(train_data.t), torch.max(train_data.t), \\\n",
    "    torch.min(val_data.t), torch.max(val_data.t), \\\n",
    "    torch.min(test_data.t), torch.max(test_data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgb.linkproppred.negative_generator import NegativeEdgeGenerator\n",
    "\n",
    "num_neg_e_per_pos = 20\n",
    "neg_sample_strategy = \"hist_rnd\" #\"rnd\"\n",
    "rnd_seed = 42\n",
    "\n",
    "# Ensure to only sample actual destination nodes as negatives.\n",
    "min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
    "\n",
    "# After successfully loading the dataset...\n",
    "if neg_sample_strategy == \"hist_rnd\":\n",
    "    historical_data = train_data\n",
    "else:\n",
    "    historical_data = None\n",
    "\n",
    "neg_sampler = NegativeEdgeGenerator(\n",
    "    dataset_name=name,\n",
    "    first_dst_id=min_dst_idx,\n",
    "    last_dst_id=max_dst_idx,\n",
    "    num_neg_e=num_neg_e_per_pos,\n",
    "    strategy=neg_sample_strategy,\n",
    "    rnd_seed=rnd_seed,\n",
    "    historical_data=historical_data,\n",
    ")\n",
    "\n",
    "# generate evaluation set\n",
    "partial_path = \"/data/mala711/GNNthesis/Baselines\"\n",
    "# generate validation negative edge set\n",
    "split_mode = \"val\"\n",
    "print(\n",
    "    f\"INFO: Start generating negative samples: {split_mode} --- {neg_sample_strategy}\"\n",
    ")\n",
    "neg_sampler.generate_negative_samples(\n",
    "    data=val_data, split_mode=split_mode, partial_path=partial_path\n",
    ")\n",
    "print(\n",
    "    f\"INFO: End of negative samples generation\"\n",
    ")\n",
    "\n",
    "# generate test negative edge set\n",
    "split_mode = \"test\"\n",
    "print(\n",
    "    f\"INFO: Start generating negative samples: {split_mode} --- {neg_sample_strategy}\"\n",
    ")\n",
    "neg_sampler.generate_negative_samples(\n",
    "    data=test_data, split_mode=split_mode, partial_path=partial_path\n",
    ")\n",
    "print(\n",
    "    f\"INFO: End of negative samples generation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgb.linkproppred.negative_sampler import NegativeEdgeSampler\n",
    "\n",
    "negative_sampler = NegativeEdgeSampler(\n",
    "    dataset_name = 'starboard',\n",
    "    first_dst_id = min_dst_idx,\n",
    "    last_dst_id = max_dst_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sampler.load_eval_set('/data/mala711/GNNthesis/Baselines/starboard_val_ns.pkl', 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST TGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dynamic Link Prediction with a TGN model with Early Stopping\n",
    "Reference: \n",
    "    - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tgn.py\n",
    "\n",
    "command for an example run:\n",
    "    python examples/linkproppred/tgbl-flight/tgn.py --data \"tgbl-flight\" --num_run 1 --seed 1\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from StarDataset import StarDataset\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.datasets import JODIEDataset\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "\n",
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "# internal imports\n",
    "from tgb.utils.utils import get_args, set_random_seed, save_results\n",
    "from tgb.linkproppred.evaluate import Evaluator\n",
    "from modules.decoder import LinkPredictor\n",
    "from modules.emb_module import GraphAttentionEmbedding\n",
    "\n",
    "from modules.early_stopping import  EarlyStopMonitor\n",
    "\n",
    "from torch_geometric.nn.models.tgn import (\n",
    "    IdentityMessage,\n",
    "    LastAggregator,\n",
    "    LastNeighborLoader,\n",
    ")\n",
    "from torch_geometric.nn import TGNMemory\n",
    "from tgb.linkproppred.dataset_pyg import PyGLinkPropPredDataset\n",
    "from tgb.linkproppred.negative_sampler import NegativeEdgeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10330/10330 [00:00<00:00, 15382.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========\n",
    "# ==========\n",
    "# ==========\n",
    "\n",
    "\n",
    "# Start...\n",
    "start_overall = timeit.default_timer()\n",
    "DATA = \"starboard\"\n",
    "\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 200\n",
    "K_VALUE = 10 \n",
    "NUM_EPOCH = 30\n",
    "SEED = 1123\n",
    "MEM_DIM = 128\n",
    "TIME_DIM = 128\n",
    "EMB_DIM = 128\n",
    "TOLERANCE = 1e-6\n",
    "PATIENCE = 5\n",
    "NUM_RUNS = 5\n",
    "SAVE = False\n",
    "NUM_NEIGHBORS = 10\n",
    "\n",
    "\n",
    "MODEL_NAME = 'TGN'\n",
    "# ==========\n",
    "\n",
    "# set the device\n",
    "gpu_num = 5\n",
    "device = torch.device(f\"cuda:{gpu_num}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# data loading\n",
    "# dataset = PyGLinkPropPredDataset(name=DATA, root=\"datasets\")\n",
    "# train_mask = dataset.train_mask\n",
    "# val_mask = dataset.val_mask\n",
    "# test_mask = dataset.test_mask\n",
    "# data = dataset.get_TemporalData()\n",
    "# data = data.to(device)\n",
    "metric = 'mrr'\n",
    "\n",
    "# Starboard data\n",
    "event_path = '/data/mala711/GNNthesis/data/Starboard/events.parquet'\n",
    "data_path = '/data/mala711/GNNthesis/data/Starboard/vessels.csv'\n",
    "val_file = '/data/mala711/GNNthesis/Baselines/starboard_val_ns.pkl'\n",
    "test_file = '/data/mala711/GNNthesis/Baselines/starboard_test_ns.pkl'\n",
    "\n",
    "val_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "self_loop = False\n",
    "with_fish = False\n",
    "date_range = ['2010-11-15', '2010-11-25']\n",
    "\n",
    "sb_data = StarDataset(event_path, data_path, date_range, with_fish, self_loop)\n",
    "\n",
    "data = sb_data.get_data().to(device)\n",
    "ind_map = sb_data.get_ind_map()\n",
    "rev_ind_map = sb_data.get_rev_ind_map()\n",
    "rev_event_dict = sb_data.get_rev_event_dict()\n",
    "\n",
    "# train_data = data[train_mask]\n",
    "# val_data = data[val_mask]\n",
    "# test_data = data[test_mask]\n",
    "\n",
    "train_data, val_data, test_data = data.train_val_test_split(val_ratio=val_ratio, test_ratio=val_ratio)\n",
    "\n",
    "train_loader = TemporalDataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "val_loader = TemporalDataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "test_loader = TemporalDataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Ensure to only sample actual destination nodes as negatives.\n",
    "min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
    "\n",
    "negative_sampler = NegativeEdgeSampler(\n",
    "    dataset_name = DATA,\n",
    "    first_dst_id = min_dst_idx,\n",
    "    last_dst_id = max_dst_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 9, 9, 9], device='cuda:5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1520, 1187, 1453, 1434, 1515, 1515,  111, 1547, 1515,  844, 2272, 1769,\n",
       "        3192,  788, 1567, 1503, 3210, 2205,  788,  468, 1432, 1454, 1447,  510,\n",
       "        1833, 1415,   35,  104, 1958, 1507,   97, 1820, 1473, 1473, 1486,  917,\n",
       "        1538, 1563, 1507,    5,  785, 1467,   50, 1415, 1494, 1434, 3185,   46,\n",
       "         991,  388, 1520,  169, 2453, 2323, 1507,   56, 1226, 3113, 3205, 1409,\n",
       "        1112, 2313,   48, 1461,  773,  778, 1399,   15,  156, 1084, 1854, 2146,\n",
       "        1391, 2064, 1487, 1420,  202, 1891, 1662, 1256, 1956, 1967, 1420, 1449,\n",
       "        1390,  185, 1409,   32, 1494, 1102, 1520, 1126, 2828, 2821, 1126, 1126,\n",
       "        1453, 1040,   60, 1226, 1820,  416, 1399, 1861,   15, 1515,  839, 1999,\n",
       "        1769, 3192, 1515, 1833, 1396, 1449, 1515,  111, 1416, 1099, 1399, 1515,\n",
       "        1102,  111,  167,  111, 1948, 2149, 1428, 3200, 1850, 1653, 1432, 2033,\n",
       "        1677, 1416,   50, 1396, 1416, 1538,  163, 1487, 1416,  158,  839, 1409,\n",
       "         338, 2651, 3205,  708, 3113,  177,   59, 1432,   18, 1716,  142,   18,\n",
       "         885,  980, 1187, 1396, 1563, 1475, 1538, 1399, 1562,  332,    5,  111,\n",
       "        1891, 1662,  839, 1019,  111, 2200, 3140, 1391, 3205, 3113, 1603, 1588,\n",
       "        1226,   15,  156, 1483,  156,   78,  885,   50, 1483, 1948, 2149, 1420,\n",
       "        1473, 1483, 1483, 1473, 2313, 1112, 1126,  708], device='cuda:5')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/tgb/datasets/tgbl_flight\n",
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "flight = PyGLinkPropPredDataset(name='tgbl-flight', root=\"datasets\")\n",
    "train_mask = flight.train_mask\n",
    "val_mask = flight.val_mask\n",
    "test_mask = flight.test_mask\n",
    "flight_data = flight.get_TemporalData()\n",
    "flight_data = flight_data.to(device)\n",
    "flight_metric = flight.eval_metric\n",
    "\n",
    "flight_train_data = flight_data[train_mask]\n",
    "flight_val_data = flight_data[val_mask]\n",
    "flight_test_data = flight_data[test_mask]\n",
    "\n",
    "f_train_loader = TemporalDataLoader(flight_train_data, batch_size=BATCH_SIZE)\n",
    "f_val_loader = TemporalDataLoader(flight_val_data, batch_size=BATCH_SIZE)\n",
    "f_test_loader = TemporalDataLoader(flight_test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Ensure to only sample actual destination nodes as negatives.\n",
    "f_min_dst_idx, f_max_dst_idx = int(flight_data.dst.min()), int(flight_data.dst.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in f_train_loader:\n",
    "    f_batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_loader = LastNeighborLoader(data.num_nodes, size=NUM_NEIGHBORS, device=device)\n",
    "\n",
    "# define the model end-to-end\n",
    "memory = TGNMemory(\n",
    "    data.num_nodes,\n",
    "    data.msg.size(-1),\n",
    "    MEM_DIM,\n",
    "    TIME_DIM,\n",
    "    message_module=IdentityMessage(data.msg.size(-1), MEM_DIM, TIME_DIM),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n",
    "\n",
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=MEM_DIM,\n",
    "    out_channels=EMB_DIM,\n",
    "    msg_dim=data.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)\n",
    "\n",
    "link_pred = LinkPredictor(in_channels=EMB_DIM).to(device)\n",
    "\n",
    "model = {'memory': memory,\n",
    "        'gnn': gnn,\n",
    "        'link_pred': link_pred}\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    set(model['memory'].parameters()) | set(model['gnn'].parameters()) | set(model['link_pred'].parameters()),\n",
    "    lr=LR,\n",
    ")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Helper vector to map global node indices to local ones.\n",
    "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:05<03:45,  5.49s/it]\n"
     ]
    }
   ],
   "source": [
    "model['memory'].train()\n",
    "model['gnn'].train()\n",
    "model['link_pred'].train()\n",
    "\n",
    "model['memory'].reset_state()  # Start with a fresh memory.\n",
    "neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "prog_bar = tqdm.tqdm(range(len(train_loader)))\n",
    "batch = batch.to(device)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
    "\n",
    "# Sample negative destination nodes.\n",
    "neg_dst = torch.randint(\n",
    "    min_dst_idx,\n",
    "    max_dst_idx + 1,\n",
    "    (src.size(0),),\n",
    "    dtype=torch.long,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "n_id = torch.cat([src, pos_dst, neg_dst]).unique()\n",
    "n_id, edge_index, e_id = neighbor_loader(n_id)\n",
    "assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "# Get updated memory of all nodes involved in the computation.\n",
    "z, last_update = model['memory'](n_id)\n",
    "z = model['gnn'](\n",
    "    z,\n",
    "    last_update,\n",
    "    edge_index,\n",
    "    data.t[e_id].to(device),\n",
    "    data.msg[e_id].to(device),\n",
    ")\n",
    "\n",
    "pos_out = model['link_pred'](z[assoc[src]], z[assoc[pos_dst]])\n",
    "neg_out = model['link_pred'](z[assoc[src]], z[assoc[neg_dst]])\n",
    "\n",
    "loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "# Update memory and neighbor loader with ground-truth state.\n",
    "model['memory'].update_state(src, pos_dst, t, msg)\n",
    "neighbor_loader.insert(src, pos_dst)\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "model['memory'].detach()\n",
    "total_loss += float(loss) * batch.num_events\n",
    "prog_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_loader(n_id)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.n_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "=================*** TGN: LinkPropPred: starboard ***=============\n",
      "==========================================================\n",
      "-------------------------------------------------------------------------------\n",
      "INFO: >>>>> Run: 0 <<<<<\n",
      "Training Epoch: 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 230\u001b[0m\n\u001b[1;32m    228\u001b[0m start_epoch_train \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m end_epoch_train \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training elapsed Time (s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_epoch_train\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_epoch_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m )\n",
      "Cell \u001b[0;32mIn[22], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(neg_out, torch\u001b[38;5;241m.\u001b[39mzeros_like(neg_out))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Update memory and neighbor loader with ground-truth state.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmemory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m neighbor_loader\u001b[38;5;241m.\u001b[39minsert(src, pos_dst)\n\u001b[1;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch_geometric/nn/models/tgn.py:110\u001b[0m, in \u001b[0;36mTGNMemory.update_state\u001b[0;34m(self, src, dst, t, raw_msg)\u001b[0m\n\u001b[1;32m    107\u001b[0m n_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src, dst])\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_msg_store(src, dst, t, raw_msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg_s_store)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_msg_store(dst, src, t, raw_msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg_d_store)\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch_geometric/nn/models/tgn.py:126\u001b[0m, in \u001b[0;36mTGNMemory._update_memory\u001b[0;34m(self, n_id)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_memory\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_id: Tensor):\n\u001b[0;32m--> 126\u001b[0m     memory, last_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_updated_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory[n_id] \u001b[38;5;241m=\u001b[39m memory\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_update[n_id] \u001b[38;5;241m=\u001b[39m last_update\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch_geometric/nn/models/tgn.py:148\u001b[0m, in \u001b[0;36mTGNMemory._get_updated_memory\u001b[0;34m(self, n_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m aggr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr_module(msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assoc[idx], t, n_id\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Get local copy of updated memory.\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Get local copy of updated `last_update`.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_update\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/mala711/miniconda3/envs/gnnthesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1438\u001b[0m, in \u001b[0;36mGRUCell.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1436\u001b[0m     hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched \u001b[38;5;28;01melse\u001b[39;00m hx\n\u001b[0;32m-> 1438\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   1445\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "# ==========\n",
    "# ========== Define helper function...\n",
    "# ==========\n",
    "\n",
    "def train():\n",
    "    r\"\"\"\n",
    "    Training procedure for TGN model\n",
    "    This function uses some objects that are globally defined in the current scrips \n",
    "\n",
    "    Parameters:\n",
    "        None\n",
    "    Returns:\n",
    "        None\n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    model['memory'].train()\n",
    "    model['gnn'].train()\n",
    "    model['link_pred'].train()\n",
    "\n",
    "    model['memory'].reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    prog_bar = tqdm.tqdm(range(len(train_loader)))\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
    "\n",
    "        # Sample negative destination nodes.\n",
    "        neg_dst = torch.randint(\n",
    "            min_dst_idx,\n",
    "            max_dst_idx + 1,\n",
    "            (src.size(0),),\n",
    "            dtype=torch.long,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # Get updated memory of all nodes involved in the computation.\n",
    "        z, last_update = model['memory'](n_id)\n",
    "        z = model['gnn'](\n",
    "            z,\n",
    "            last_update,\n",
    "            edge_index,\n",
    "            data.t[e_id].to(device),\n",
    "            data.msg[e_id].to(device),\n",
    "        )\n",
    "\n",
    "        pos_out = model['link_pred'](z[assoc[src]], z[assoc[pos_dst]])\n",
    "        neg_out = model['link_pred'](z[assoc[src]], z[assoc[neg_dst]])\n",
    "\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "        # Update memory and neighbor loader with ground-truth state.\n",
    "        model['memory'].update_state(src, pos_dst, t, msg)\n",
    "        neighbor_loader.insert(src, pos_dst)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model['memory'].detach()\n",
    "        total_loss += float(loss) * batch.num_events\n",
    "        prog_bar.update(1)\n",
    "    prog_bar.close()\n",
    "\n",
    "    return total_loss / train_data.num_events\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader, neg_sampler, split_mode):\n",
    "    r\"\"\"\n",
    "    Evaluated the dynamic link prediction\n",
    "    Evaluation happens as 'one vs. many', meaning that each positive edge is evaluated against many negative edges\n",
    "\n",
    "    Parameters:\n",
    "        loader: an object containing positive attributes of the positive edges of the evaluation set\n",
    "        neg_sampler: an object that gives the negative edges corresponding to each positive edge\n",
    "        split_mode: specifies whether it is the 'validation' or 'test' set to correctly load the negatives\n",
    "    Returns:\n",
    "        perf_metric: the result of the performance evaluation\n",
    "    \"\"\"\n",
    "    model['memory'].eval()\n",
    "    model['gnn'].eval()\n",
    "    model['link_pred'].eval()\n",
    "\n",
    "    perf_list = []\n",
    "\n",
    "    prog_bar = tqdm.tqdm(range(len(loader)))\n",
    "    for pos_batch in loader:\n",
    "        pos_src, pos_dst, pos_t, pos_msg = (\n",
    "            pos_batch.src,\n",
    "            pos_batch.dst,\n",
    "            pos_batch.t,\n",
    "            pos_batch.msg,\n",
    "        )\n",
    "\n",
    "        neg_batch_list = neg_sampler.query_batch(pos_src, pos_dst, pos_t, split_mode=split_mode)\n",
    "\n",
    "        for idx, neg_batch in enumerate(neg_batch_list):\n",
    "            src = torch.full((1 + len(neg_batch),), pos_src[idx], device=device)\n",
    "            dst = torch.tensor(\n",
    "                np.concatenate(\n",
    "                    ([np.array([pos_dst.cpu().numpy()[idx]]), np.array(neg_batch)]),\n",
    "                    axis=0,\n",
    "                ),\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "            assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "            # Get updated memory of all nodes involved in the computation.\n",
    "            z, last_update = model['memory'](n_id)\n",
    "            z = model['gnn'](\n",
    "                z,\n",
    "                last_update,\n",
    "                edge_index,\n",
    "                data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device),\n",
    "            )\n",
    "\n",
    "            y_pred = model['link_pred'](z[assoc[src]], z[assoc[dst]])\n",
    "\n",
    "            # compute MRR\n",
    "            input_dict = {\n",
    "                \"y_pred_pos\": np.array([y_pred[0, :].squeeze(dim=-1).cpu()]),\n",
    "                \"y_pred_neg\": np.array(y_pred[1:, :].squeeze(dim=-1).cpu()),\n",
    "                \"eval_metric\": [metric],\n",
    "            }\n",
    "            perf_list.append(evaluator.eval(input_dict)[metric])\n",
    "\n",
    "        # Update memory and neighbor loader with ground-truth state.\n",
    "        model['memory'].update_state(pos_src, pos_dst, pos_t, pos_msg)\n",
    "        neighbor_loader.insert(pos_src, pos_dst)\n",
    "    \n",
    "        prog_bar.update(1)\n",
    "    prog_bar.close()\n",
    "\n",
    "    perf_metrics = float(torch.tensor(perf_list).mean())\n",
    "\n",
    "    return perf_metrics\n",
    "\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(f\"=================*** {MODEL_NAME}: LinkPropPred: {DATA} ***=============\")\n",
    "print(\"==========================================================\")\n",
    "\n",
    "evaluator = Evaluator(name=DATA)\n",
    "neg_sampler = negative_sampler\n",
    "\n",
    "# for saving the results...\n",
    "\n",
    "if SAVE:\n",
    "    results_path = f'/data/mala711/GNNthesis/Baselines/saved_results'\n",
    "    if not osp.exists(results_path):\n",
    "        os.mkdir(results_path)\n",
    "        print('INFO: Create directory {}'.format(results_path))\n",
    "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
    "    results_filename = f'{results_path}/{MODEL_NAME}_{DATA}_results.json'\n",
    "\n",
    "for run_idx in range(NUM_RUNS):\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "    print(f\"INFO: >>>>> Run: {run_idx} <<<<<\")\n",
    "    start_run = timeit.default_timer()\n",
    "\n",
    "    # set the seed for deterministic results...\n",
    "    # torch.manual_seed(run_idx + SEED)\n",
    "    # set_random_seed(run_idx + SEED)\n",
    "\n",
    "    # neighborhood sampler\n",
    "    neighbor_loader = LastNeighborLoader(data.num_nodes, size=NUM_NEIGHBORS, device=device)\n",
    "\n",
    "    # define the model end-to-end\n",
    "    memory = TGNMemory(\n",
    "        data.num_nodes,\n",
    "        data.msg.size(-1),\n",
    "        MEM_DIM,\n",
    "        TIME_DIM,\n",
    "        message_module=IdentityMessage(data.msg.size(-1), MEM_DIM, TIME_DIM),\n",
    "        aggregator_module=LastAggregator(),\n",
    "    ).to(device)\n",
    "\n",
    "    gnn = GraphAttentionEmbedding(\n",
    "        in_channels=MEM_DIM,\n",
    "        out_channels=EMB_DIM,\n",
    "        msg_dim=data.msg.size(-1),\n",
    "        time_enc=memory.time_enc,\n",
    "    ).to(device)\n",
    "\n",
    "    link_pred = LinkPredictor(in_channels=EMB_DIM).to(device)\n",
    "\n",
    "    model = {'memory': memory,\n",
    "            'gnn': gnn,\n",
    "            'link_pred': link_pred}\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        set(model['memory'].parameters()) | set(model['gnn'].parameters()) | set(model['link_pred'].parameters()),\n",
    "        lr=LR,\n",
    "    )\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Helper vector to map global node indices to local ones.\n",
    "    assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "    # define an early stopper\n",
    "    if SAVE:\n",
    "        save_model_dir = f'{osp.dirname(osp.abspath(__file__))}/saved_models/'\n",
    "        save_model_id = f'{MODEL_NAME}_{DATA}_{SEED}_{run_idx}'\n",
    "        early_stopper = EarlyStopMonitor(save_model_dir=save_model_dir, save_model_id=save_model_id, \n",
    "                                        tolerance=TOLERANCE, patience=PATIENCE)\n",
    "\n",
    "    # ==================================================== Train & Validation\n",
    "    # loading the validation negative samples\n",
    "    neg_sampler.load_eval_set(val_file, 'val')\n",
    "\n",
    "    val_perf_list = []\n",
    "    train_times_l, val_times_l = [], []\n",
    "    free_mem_l, total_mem_l, used_mem_l = [], [], []\n",
    "    start_train_val = timeit.default_timer()\n",
    "    for epoch in range(1, NUM_EPOCH + 1):\n",
    "        # training\n",
    "        start_epoch_train = timeit.default_timer()\n",
    "        print(f'Training Epoch: {epoch:02d}')\n",
    "        loss = train()\n",
    "        end_epoch_train = timeit.default_timer()\n",
    "        print(\n",
    "            f\"Loss: {loss:.4f}, Training elapsed Time (s): {end_epoch_train - start_epoch_train: .4f}\"\n",
    "        )\n",
    "        # checking GPU memory usage\n",
    "        free_mem, used_mem, total_mem = 0, 0, 0\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"DEBUG: device: {}\".format(torch.cuda.get_device_name(0)))\n",
    "            free_mem, total_mem = torch.cuda.mem_get_info()\n",
    "            used_mem = total_mem - free_mem\n",
    "            print(\"------------Epoch {}: GPU memory usage-----------\".format(epoch))\n",
    "            print(\"Free memory: {}\".format(free_mem))\n",
    "            print(\"Total available memory: {}\".format(total_mem))\n",
    "            print(\"Used memory: {}\".format(used_mem))\n",
    "            print(\"--------------------------------------------\")\n",
    "        \n",
    "        train_times_l.append(end_epoch_train - start_epoch_train)\n",
    "        free_mem_l.append(float((free_mem*1.0)/2**30))  # in GB\n",
    "        used_mem_l.append(float((used_mem*1.0)/2**30))  # in GB\n",
    "        total_mem_l.append(float((total_mem*1.0)/2**30))  # in GB\n",
    "\n",
    "        # validation\n",
    "        start_val = timeit.default_timer()\n",
    "        perf_metric_val = test(val_loader, neg_sampler, split_mode=\"val\")\n",
    "        end_val = timeit.default_timer()\n",
    "        print(f\"\\tValidation {metric}: {perf_metric_val: .4f}\")\n",
    "        print(f\"\\tValidation: Elapsed time (s): {end_val - start_val: .4f}\")\n",
    "        val_perf_list.append(perf_metric_val)\n",
    "        val_times_l.append(end_val - start_val)\n",
    "\n",
    "        # check for early stopping\n",
    "        if early_stopper.step_check(perf_metric_val, model):\n",
    "            break\n",
    "\n",
    "    train_val_time = timeit.default_timer() - start_train_val\n",
    "    print(f\"Train & Validation: Elapsed Time (s): {train_val_time: .4f}\")\n",
    "\n",
    "    # ==================================================== Test\n",
    "    # first, load the best model\n",
    "    early_stopper.load_checkpoint(model)\n",
    "\n",
    "    # loading the test negative samples\n",
    "    neg_sampler.load_eval_set(test_file, 'test')\n",
    "\n",
    "    # final testing\n",
    "    start_test = timeit.default_timer()\n",
    "    perf_metric_test = test(test_loader, neg_sampler, split_mode=\"test\")\n",
    "\n",
    "    print(f\"INFO: Test: Evaluation Setting: >>> ONE-VS-MANY <<< \")\n",
    "    print(f\"\\tTest: {metric}: {perf_metric_test: .4f}\")\n",
    "    test_time = timeit.default_timer() - start_test\n",
    "    print(f\"\\tTest: Elapsed Time (s): {test_time: .4f}\")\n",
    "\n",
    "    if SAVE:\n",
    "        save_results({'data': DATA,\n",
    "                    'model': MODEL_NAME,\n",
    "                    'run': run_idx,\n",
    "                    'seed': SEED,\n",
    "                    'train_times': train_times_l,\n",
    "                    'free_mem': free_mem_l,\n",
    "                    'total_mem': total_mem_l,\n",
    "                    'used_mem': used_mem_l,\n",
    "                    'max_used_mem': max(used_mem_l),\n",
    "                    'val_times': val_times_l,\n",
    "                    f'val {metric}': val_perf_list,\n",
    "                    f'test {metric}': perf_metric_test,\n",
    "                    'test_time': test_time,\n",
    "                    'train_val_total_time': np.sum(np.array(train_times_l)) + np.sum(np.array(val_times_l)),\n",
    "                    }, \n",
    "        results_filename)\n",
    "\n",
    "    print(f\"INFO: >>>>> Run: {run_idx}, elapsed time: {timeit.default_timer() - start_run: .4f} <<<<<\")\n",
    "    print('-------------------------------------------------------------------------------')\n",
    "\n",
    "print(f\"Overall Elapsed Time (s): {timeit.default_timer() - start_overall: .4f}\")\n",
    "print(\"==============================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
