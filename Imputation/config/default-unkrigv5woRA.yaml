defaults:
  - _self_
  - logger: null
  - dataset: metrla
  - model: unkrigv5woRA

#### Experiment params ########################################################
hydra:
  run:
    # dir: logs/unkrigv5/aqi/2025-06-19/19-32-15
    dir: logs/${model.name}/${dataset.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: logs/${now:%Y-%m-%d-%H-%M-%S}
    subdir: ${model.name}/${dataset.name}/${hydra.job.num}

# seed: 87654321  # automatically set everywhere the seed
tags:
  - ${model.name}
  - ${dataset.name}

# Replace with the last ckpt file to resume training
# call_path: logs/unkrigv5/aqi/2025-06-19/19-32-15/epoch=82-last.ckpt
call_path: null
workers: 0
num_threads: 1  # limit the number of pytorch threads spawn

logger: tensorboard

#### Windowing params #########################################################
window: 24
stride: 1

#### Training params ##########################################################
epochs: 200
patience: 50
batch_size: 64
grad_clip_val: 1
grad_clip_alg: 'norm'
scale_target: True
whiten_prob: 0.05
prediction_loss_weight: 1
impute_only_missing: False
warm_up_steps: 0
device: [0]
eval_setting: 'train_wise'
num_groups: 4

detrend: False
scale: True
scaling_axis: 'global'  # ['channels', 'global']

optimizer:
  name: Adam
  hparams:
    lr: 0.00007
    weight_decay: 0.

lr_scheduler:
  name: CosineAnnealingLR
  hparams:
      eta_min: 0.0001
      T_max: ${ epochs }