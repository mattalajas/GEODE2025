{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "# from torch_geometric import nn as tgnn\n",
    "from preprocessing import sparse_to_tuple\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils import *\n",
    "import torch_scatter\n",
    "import inspect\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tqdm\n",
    "\n",
    "from models import *\n",
    "\n",
    "# utility functions\n",
    "\n",
    "def uniform(size, tensor):\n",
    "    stdv = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "def glorot(tensor):\n",
    "    stdv = math.sqrt(6.0 / (tensor.size(0) + tensor.size(1)))\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)\n",
    "\n",
    "\n",
    "def ones(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(1)\n",
    "\n",
    "\n",
    "def reset(nn):\n",
    "    def _reset(item):\n",
    "        if hasattr(item, 'reset_parameters'):\n",
    "            item.reset_parameters()\n",
    "\n",
    "    if nn is not None:\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
    "            for item in nn.children():\n",
    "                _reset(item)\n",
    "        else:\n",
    "            _reset(nn)\n",
    "\n",
    "\n",
    "def scatter_(name, src, index, dim_size=None):\n",
    "    r\"\"\"Aggregates all values from the :attr:`src` tensor at the indices\n",
    "    specified in the :attr:`index` tensor along the first dimension.\n",
    "    If multiple indices reference the same location, their contributions\n",
    "    are aggregated according to :attr:`name` (either :obj:`\"add\"`,\n",
    "    :obj:`\"mean\"` or :obj:`\"max\"`).\n",
    "    Args:\n",
    "        name (string): The aggregation to use (:obj:`\"add\"`, :obj:`\"mean\"`,\n",
    "            :obj:`\"max\"`).\n",
    "        src (Tensor): The source tensor.\n",
    "        index (LongTensor): The indices of elements to scatter.\n",
    "        dim_size (int, optional): Automatically create output tensor with size\n",
    "            :attr:`dim_size` in the first dimension. If set to :attr:`None`, a\n",
    "            minimal sized output tensor is returned. (default: :obj:`None`)\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "\n",
    "    assert name in ['sum', 'mean', 'max']\n",
    "\n",
    "    op = getattr(torch_scatter, 'scatter_{}'.format(name))\n",
    "    fill_value = -1e38 if name == 'max' else 0\n",
    "    print(op(src, index, dim_size=dim_size))\n",
    "\n",
    "    out = op(src, index, dim = 0, dim_size = dim_size, fill_value = fill_value)\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "\n",
    "    if name == 'max':\n",
    "        out[out == fill_value] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def tuple_to_array(lot):\n",
    "    out = np.array(list(lot[0]))\n",
    "    for i in range(1, len(lot)):\n",
    "        out = np.vstack((out, np.array(list(lot[i]))))\n",
    "    \n",
    "    return out\n",
    "\n",
    "# masking functions\n",
    "\n",
    "def mask_edges_det_t(adjs_list):\n",
    "    adj_train_l, train_edges_l, val_edges_l = [], [], []\n",
    "    val_edges_false_l, test_edges_l, test_edges_false_l = [], [], []\n",
    "    edges_list = []\n",
    "\n",
    "    pbar = tqdm.tqdm(total=len(adjs_list))\n",
    "    for i in range(0, len(adjs_list)):\n",
    "        # Function to build test set with 10% positive links\n",
    "        # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "        \n",
    "        adj = adjs_list[i]\n",
    "        # Remove diagonal elements\n",
    "        adj = torch.abs(torch.eye(adj.shape[0])*adj - adj)\n",
    "        # Check that diag is zero:\n",
    "        assert np.diag(adj.to_dense()).sum() == 0\n",
    "        \n",
    "        # Return upper triangle part of array (assumes bidirectional)\n",
    "        adj_triu = adj.to_dense().triu()\n",
    "        edges = torch.nonzero(adj_triu)\n",
    "\n",
    "        # All edges\n",
    "        edges_all = torch.nonzero(adj.to_dense())\n",
    "        num_test = int(np.ceil(edges.shape[0]*.10))\n",
    "        num_val = int(np.ceil(edges.shape[0]*.20))\n",
    "        \n",
    "        # Splits all edges to test val train\n",
    "        all_edge_idx = np.arange(edges.shape[0])\n",
    "        np.random.shuffle(all_edge_idx)\n",
    "        val_edge_idx = all_edge_idx[:num_val]\n",
    "        test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "        test_edges = edges[test_edge_idx]\n",
    "        val_edges = edges[val_edge_idx]\n",
    "        train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "        \n",
    "        edges_list.append(edges)\n",
    "        \n",
    "        def ismember(a, b, tol=5):\n",
    "            rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
    "            return np.any(rows_close)\n",
    "\n",
    "        test_edges_false = []\n",
    "        # Get false test edges 1:1 ratio\n",
    "        while len(test_edges_false) < len(test_edges):\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if test_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
    "                    continue\n",
    "            test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        val_edges_false = []\n",
    "        # Get val edges 1:1 ratio\n",
    "        while len(val_edges_false) < len(val_edges):\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], val_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], val_edges):\n",
    "                continue\n",
    "            if val_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
    "                    continue\n",
    "            val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        assert ~ismember(test_edges_false, edges_all)\n",
    "        assert ~ismember(val_edges_false, edges_all)\n",
    "        assert ~ismember(val_edges, train_edges)\n",
    "        assert ~ismember(test_edges, train_edges)\n",
    "        assert ~ismember(val_edges, test_edges)\n",
    "\n",
    "        data = np.ones(train_edges.shape[0])\n",
    "\n",
    "        # Re-build adj matrix\n",
    "        adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
    "        adj_train = adj_train + adj_train.T\n",
    "\n",
    "        # Adj_train is full matrix\n",
    "        adj_train_l.append(adj_train)\n",
    "        train_edges_l.append(train_edges)\n",
    "        val_edges_l.append(val_edges)\n",
    "        val_edges_false_l.append(val_edges_false)\n",
    "        test_edges_l.append(test_edges)\n",
    "        test_edges_false_l.append(test_edges_false)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return adj_train_l, train_edges_l, val_edges_l, val_edges_false_l, test_edges_l, test_edges_false_l\n",
    "\n",
    "def mask_edges_prd_t(adjs_list):\n",
    "    pos_edges_l , false_edges_l = [], []\n",
    "    edges_list = []\n",
    "\n",
    "    pbar = tqdm.tqdm(total=len(adjs_list))\n",
    "    for i in range(0, len(adjs_list)):\n",
    "        # Function to build test set with 10% positive links\n",
    "        # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "        \n",
    "        adj = adjs_list[i]\n",
    "        # Remove diagonal elements\n",
    "        adj = torch.abs(torch.eye(adj.shape[0])*adj - adj)\n",
    "        # Check that diag is zero:\n",
    "        assert np.diag(adj.todense()).sum() == 0\n",
    "        \n",
    "        # Return upper triangle part of array (assumes bidirectional)\n",
    "        adj_triu = sp.triu(adj)\n",
    "        adj_tuple = sparse_to_tuple(adj_triu)\n",
    "        edges = adj_tuple[0]\n",
    "\n",
    "        # All edges\n",
    "        edges_all = sparse_to_tuple(adj)[0]\n",
    "        num_false = int(edges.shape[0])\n",
    "        \n",
    "        # Positive edges\n",
    "        pos_edges_l.append(edges)\n",
    "        \n",
    "        def ismember(a, b, tol=5):\n",
    "            rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
    "            return np.any(rows_close)\n",
    "        \n",
    "        # Retrieve negative edges\n",
    "        edges_false = []\n",
    "        while len(edges_false) < num_false:\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(edges_false)):\n",
    "                    continue\n",
    "            edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        assert ~ismember(edges_false, edges_all)\n",
    "        \n",
    "        false_edges_l.append(edges_false)\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return pos_edges_l, false_edges_l\n",
    "\n",
    "def mask_edges_prd_new_t(adjs_list):\n",
    "    pos_edges_l , false_edges_l = [], []\n",
    "    edges_list = []\n",
    "    \n",
    "    # Function to build test set with 10% positive links\n",
    "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "\n",
    "    adj = adjs_list[0]\n",
    "    # Remove diagonal elements\n",
    "    adj = torch.abs(torch.eye(adj.shape[0])*adj - adj)\n",
    "    # Check that diag is zero:\n",
    "    assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "    # Return upper triangle part of array (assumes bidirectional)\n",
    "    adj_triu = sp.triu(adj)\n",
    "    adj_tuple = sparse_to_tuple(adj_triu)\n",
    "    edges = adj_tuple[0]\n",
    "\n",
    "    # All edges\n",
    "    edges_all = sparse_to_tuple(adj)[0]\n",
    "    num_false = int(edges.shape[0])\n",
    "\n",
    "    # Positive edges\n",
    "    pos_edges_l.append(edges)\n",
    "\n",
    "    def ismember(a, b, tol=5):\n",
    "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
    "        return np.any(rows_close)\n",
    "\n",
    "    # Generate negative edges\n",
    "    edges_false = []\n",
    "    while len(edges_false) < num_false:\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "        if ismember([idx_i, idx_j], edges_all):\n",
    "            continue\n",
    "        if edges_false:\n",
    "            if ismember([idx_j, idx_i], np.array(edges_false)):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], np.array(edges_false)):\n",
    "                continue\n",
    "        edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    assert ~ismember(edges_false, edges_all)    \n",
    "    false_edges_l.append(np.asarray(edges_false))\n",
    "    \n",
    "    pbar = tqdm.tqdm(total=len(adjs_list))\n",
    "    for i in range(1, len(adjs_list)):\n",
    "        # Get newly generated edges \n",
    "        edges_pos = np.transpose(np.asarray(np.nonzero((adjs_list[i] - adjs_list[i-1])>0)))\n",
    "        num_false = int(edges_pos.shape[0])\n",
    "        \n",
    "        adj = adjs_list[i]\n",
    "        # Remove diagonal elements\n",
    "        adj = torch.abs(torch.eye(adj.shape[0])*adj - adj)\n",
    "        # Check that diag is zero:\n",
    "        assert np.diag(adj.todense()).sum() == 0\n",
    "        \n",
    "        # Get upper triangle part of array (assumes bidirectional)\n",
    "        adj_triu = sp.triu(adj)\n",
    "        adj_tuple = sparse_to_tuple(adj_triu)\n",
    "        edges = adj_tuple[0]\n",
    "        edges_all = sparse_to_tuple(adj)[0]\n",
    "        \n",
    "        # Get negative edges for each newly generated edge\n",
    "        edges_false = []\n",
    "        while len(edges_false) < num_false:\n",
    "            idx_i = np.random.randint(0, adj.shape[0])\n",
    "            idx_j = np.random.randint(0, adj.shape[0])\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(edges_false)):\n",
    "                    continue\n",
    "            edges_false.append([idx_i, idx_j])\n",
    "        \n",
    "        assert ~ismember(edges_false, edges_all)\n",
    "        \n",
    "        false_edges_l.append(np.asarray(edges_false))\n",
    "        pos_edges_l.append(edges_pos)\n",
    "    \n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return pos_edges_l, false_edges_l\n",
    "\n",
    "# evaluation function\n",
    "\n",
    "def get_roc_scores(edges_pos, edges_neg, adj_orig_dense_list, embs):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    auc_scores = []\n",
    "    ap_scores = []\n",
    "    \n",
    "    for i in range(len(edges_pos)):\n",
    "        # Predict on test set of edges\n",
    "        emb = embs[i].detach().numpy()\n",
    "        adj_rec = np.dot(emb, emb.T)\n",
    "        adj_orig_t = adj_orig_dense_list[i].todense()\n",
    "        preds = []\n",
    "        pos = []\n",
    "        for e in edges_pos[i]:\n",
    "            preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "            pos.append(adj_orig_t[e[0], e[1]])\n",
    "            \n",
    "        preds_neg = []\n",
    "        neg = []\n",
    "        for e in edges_neg[i]:\n",
    "            preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "            neg.append(adj_orig_t[e[0], e[1]])\n",
    "        \n",
    "        preds_all = np.hstack([preds, preds_neg])\n",
    "        labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "        auc_scores.append(roc_auc_score(labels_all, preds_all))\n",
    "        ap_scores.append(average_precision_score(labels_all, preds_all))\n",
    "\n",
    "    return auc_scores, ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "# from torch_geometric import nn as tgnn\n",
    "from preprocessing import sparse_to_tuple, get_starboard_data\n",
    "import scipy.sparse as sp\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch_scatter import scatter_mean, scatter_max, scatter_add\n",
    "from torch_geometric.utils import *\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_scatter\n",
    "import inspect\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import copy\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "from models import *\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "cuda_num = 5\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else f'cuda:{cuda_num}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/mala711/GNNthesis/data/Starboard/adj_time_list.pickle', 'rb') as handle:\n",
    "    adj_time_list = pickle.load(handle)\n",
    "\n",
    "interval = -460\n",
    "interval = -50\n",
    "adj_time_list = adj_time_list[interval:]\n",
    "\n",
    "adj_time_list_t = torch.stack(adj_time_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build test set with 10% positive links\n",
    "# NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "\n",
    "adj = adj_time_list_t[0].to(device)\n",
    "# Remove diagonal elements\n",
    "adj = torch.abs(torch.eye(adj.shape[0]).to(device)*adj - adj)\n",
    "adj_all = adj + adj.T\n",
    "# Check that diag is zero:\n",
    "assert torch.diag(adj.to_dense()).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return upper triangle part of array (assumes bidirectional)\n",
    "edges = torch.nonzero(adj.to_dense())\n",
    "\n",
    "# All edges\n",
    "edges_all = torch.nonzero(adj_all.to_dense())\n",
    "num_test = int(np.ceil(edges.shape[0]*.10))\n",
    "num_val = int(np.ceil(edges.shape[0]*.20))\n",
    "\n",
    "# Splits all edges to test val train\n",
    "all_edge_idx = torch.randperm(edges.shape[0])\n",
    "val_edge_idx = all_edge_idx[:num_val]\n",
    "test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "test_edges = edges[test_edge_idx]\n",
    "val_edges = edges[val_edge_idx]\n",
    "train_edges = edges[~(torch.hstack([test_edge_idx, val_edge_idx]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ismember(a, b):\n",
    "    rows_close = torch.all(torch.round(a - b[:, None]) == 0, dim = 1)\n",
    "    return torch.any(rows_close)\n",
    "\n",
    "test_edges_false = torch.empty(0).to(device)\n",
    "# Get false test edges 1:1 ratio\n",
    "while len(test_edges_false) < len(test_edges):\n",
    "    idx_i = np.random.randint(0, adj.shape[0])\n",
    "    idx_j = np.random.randint(0, adj.shape[0])\n",
    "    coord1 = torch.Tensor([idx_i, idx_j]).to(device)\n",
    "    coord2 = torch.Tensor([idx_j, idx_i]).to(device)\n",
    "    if idx_i == idx_j:\n",
    "        continue\n",
    "    if ismember(coord1, edges_all):\n",
    "        continue\n",
    "    if test_edges_false.shape[0] > 0:\n",
    "        if ismember(coord1, test_edges_false):\n",
    "            continue\n",
    "        if ismember(coord2, test_edges_false):\n",
    "            continue\n",
    "    test_edges_false = torch.cat((test_edges_false, coord1), 0)\n",
    "test_edges_false = test_edges_false.reshape(-1, 2)\n",
    "\n",
    "val_edges_false = torch.empty(0).to(device)\n",
    "# Get val edges 1:1 ratio\n",
    "while len(val_edges_false) < len(val_edges):\n",
    "    idx_i = np.random.randint(0, adj.shape[0])\n",
    "    idx_j = np.random.randint(0, adj.shape[0])\n",
    "    coord1 = torch.Tensor([idx_i, idx_j]).to(device)\n",
    "    coord2 = torch.Tensor([idx_j, idx_i]).to(device)\n",
    "    if idx_i == idx_j:\n",
    "        continue\n",
    "    if ismember(coord1, train_edges):\n",
    "        continue\n",
    "    if ismember(coord2, train_edges):\n",
    "        continue\n",
    "    if ismember(coord1, val_edges):\n",
    "        continue\n",
    "    if ismember(coord2, val_edges):\n",
    "        continue\n",
    "    if val_edges_false.shape[0] > 0:\n",
    "        if ismember(coord1, val_edges_false):\n",
    "            continue\n",
    "        if ismember(coord2, val_edges_false):\n",
    "            continue\n",
    "    val_edges_false = torch.cat((val_edges_false, coord1), 0)\n",
    "val_edges_false = val_edges_false.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1573,  1400],\n",
       "        [ 2224,  1932],\n",
       "        [ 4221,  1012],\n",
       "        [ 8130,   576],\n",
       "        [  375,  2021],\n",
       "        [ 3246,  2227],\n",
       "        [ 9475,  6955],\n",
       "        [ 1581,   600],\n",
       "        [ 8408, 10802],\n",
       "        [ 1868, 10751],\n",
       "        [ 9515,   978],\n",
       "        [ 1510,  1365],\n",
       "        [ 4205,  3966],\n",
       "        [ 8093,  1636],\n",
       "        [ 1163,  1302],\n",
       "        [ 3494,  5897],\n",
       "        [ 3722,  3723],\n",
       "        [ 5392,  6349],\n",
       "        [ 5324,  1437],\n",
       "        [ 6224,  1095],\n",
       "        [   58,    59],\n",
       "        [ 8520,  2288],\n",
       "        [ 4837,  1880],\n",
       "        [ 2862,  2150],\n",
       "        [ 6387,  3656],\n",
       "        [ 5185,   951],\n",
       "        [ 3166,  1854],\n",
       "        [ 1720,  5439],\n",
       "        [ 1599,  7378],\n",
       "        [ 2774,  1863],\n",
       "        [ 8057,  5229],\n",
       "        [ 6068,  1773],\n",
       "        [ 2611,  1184],\n",
       "        [ 1423,  6706],\n",
       "        [ 6200,  1166],\n",
       "        [ 7829,  1336],\n",
       "        [ 3429,  3212],\n",
       "        [ 4724,  1910],\n",
       "        [ 9568,  1134],\n",
       "        [ 5764,  4045],\n",
       "        [ 2154,  3909],\n",
       "        [ 4590,  5872],\n",
       "        [ 7501,  2256],\n",
       "        [ 1859,  1854],\n",
       "        [11095,  5113],\n",
       "        [ 5401,  1299],\n",
       "        [ 3456,  8034],\n",
       "        [  754,  4680],\n",
       "        [ 6070,  1660],\n",
       "        [ 3492,  3519],\n",
       "        [10945,  4948],\n",
       "        [ 8130,  2985],\n",
       "        [10390,  1365],\n",
       "        [ 7053,    84],\n",
       "        [ 9499,  4583],\n",
       "        [ 1535,  2545],\n",
       "        [ 2369,  6055],\n",
       "        [ 4197,  1854],\n",
       "        [ 2534,    25],\n",
       "        [ 3718,  4822],\n",
       "        [ 1998,  1999],\n",
       "        [11333, 11349],\n",
       "        [ 1480,   576],\n",
       "        [11036,  8264],\n",
       "        [ 3179,  2967],\n",
       "        [   24,    25],\n",
       "        [ 3089,  1400],\n",
       "        [ 6143,  3751],\n",
       "        [ 3555,  2267],\n",
       "        [ 3743,  4762],\n",
       "        [ 1083,  1084],\n",
       "        [ 2125,    25],\n",
       "        [10026,  1400],\n",
       "        [ 2887,  6949],\n",
       "        [ 5989,  3026],\n",
       "        [ 5814,  1180],\n",
       "        [10787,  1537],\n",
       "        [ 4202,  3015],\n",
       "        [ 6715,  7428],\n",
       "        [ 5053,    25],\n",
       "        [ 9862,  8716],\n",
       "        [  163,   405],\n",
       "        [ 7332,  4951],\n",
       "        [10549,  2726],\n",
       "        [10012,  8325],\n",
       "        [ 2582,  1302],\n",
       "        [ 5760,  4915],\n",
       "        [ 3909,  2154],\n",
       "        [ 5366,  6388],\n",
       "        [ 3281,   308],\n",
       "        [ 6563,  7503],\n",
       "        [ 2679,  4680],\n",
       "        [ 3248, 10835],\n",
       "        [ 2759,   930],\n",
       "        [ 5954,  1660],\n",
       "        [ 3690,  1012],\n",
       "        [ 5581,  2860],\n",
       "        [  978,  9515],\n",
       "        [ 5613,  5614],\n",
       "        [  822,   263],\n",
       "        [    7,     8],\n",
       "        [10915,  1067],\n",
       "        [  976,   752],\n",
       "        [   11,    12],\n",
       "        [ 8073,  7887],\n",
       "        [ 3011,  2586],\n",
       "        [ 1404, 10704],\n",
       "        [11143,  2861],\n",
       "        [ 9560,  1400],\n",
       "        [  269,   598],\n",
       "        [11008,  1676],\n",
       "        [ 3627,  2523],\n",
       "        [ 1695,  2402],\n",
       "        [  511,  6748],\n",
       "        [  374,  1490],\n",
       "        [ 5883,   600],\n",
       "        [ 7115,  2379],\n",
       "        [ 8132,  8729],\n",
       "        [ 8332,  1861],\n",
       "        [ 5239,  7012],\n",
       "        [ 7532,  8585],\n",
       "        [ 3747,  2016],\n",
       "        [ 2549,  3074],\n",
       "        [ 1866,  1180],\n",
       "        [ 6682,   604],\n",
       "        [ 2432,  4858],\n",
       "        [ 7156, 10196],\n",
       "        [ 2573,   598],\n",
       "        [ 3659,  1522],\n",
       "        [ 5257,  1745],\n",
       "        [ 6040,  1861],\n",
       "        [ 2848,  1012],\n",
       "        [ 1563,  2334],\n",
       "        [  408,  1840],\n",
       "        [ 1708,  3196],\n",
       "        [ 5386,  3905],\n",
       "        [ 1183,  1184],\n",
       "        [ 5151,  4881],\n",
       "        [11102,  1302],\n",
       "        [ 8565,  5356],\n",
       "        [11249,  2311],\n",
       "        [ 3163,  2018],\n",
       "        [ 3048,  2278],\n",
       "        [ 4701,  4901],\n",
       "        [ 1047,  4426],\n",
       "        [ 5242,  5243],\n",
       "        [ 3095,  3160],\n",
       "        [ 8093,  1384],\n",
       "        [ 2849,   598],\n",
       "        [ 2233,  5377],\n",
       "        [ 5511,  4500],\n",
       "        [ 2433,  1703],\n",
       "        [ 1744,  5695],\n",
       "        [ 5366,  3280],\n",
       "        [ 2411,  1365],\n",
       "        [ 5193,  4267],\n",
       "        [ 2527,  1915],\n",
       "        [ 1717,  3288],\n",
       "        [ 6556,  4060],\n",
       "        [ 3151,  1904],\n",
       "        [ 3041,  3042],\n",
       "        [ 1700,  1701],\n",
       "        [  773,  5214],\n",
       "        [ 6977,  3966],\n",
       "        [ 3808,  2110],\n",
       "        [ 4272,  1932],\n",
       "        [ 5522,  3074],\n",
       "        [ 9671,  7320],\n",
       "        [11355,  2298],\n",
       "        [ 8654,   600],\n",
       "        [ 2140,  7556],\n",
       "        [ 2550,  2161],\n",
       "        [ 5684,  2016],\n",
       "        [ 7842,  2161],\n",
       "        [ 1783, 10493],\n",
       "        [ 6318,  1880],\n",
       "        [ 5490,  3640],\n",
       "        [10012,  6504],\n",
       "        [ 3075,  7708],\n",
       "        [ 7247, 11485],\n",
       "        [ 3139,  2334],\n",
       "        [ 7304,  3952],\n",
       "        [ 5026,  2908],\n",
       "        [ 6801,  3801],\n",
       "        [ 1379,  9166],\n",
       "        [ 3742,  1539],\n",
       "        [ 6468,  7982],\n",
       "        [ 2424,  5759],\n",
       "        [   21,  3907],\n",
       "        [ 4206,  1765],\n",
       "        [ 2966,  2967],\n",
       "        [10704,  1404],\n",
       "        [ 1346,  1070],\n",
       "        [ 2504,  1365],\n",
       "        [ 8093,  2527],\n",
       "        [ 8224,  1956],\n",
       "        [ 5097,  3417],\n",
       "        [10663,  7261],\n",
       "        [ 3046,   600],\n",
       "        [ 3155,  3086],\n",
       "        [ 6289,  3526],\n",
       "        [ 3729,  2808],\n",
       "        [ 2017,  4339],\n",
       "        [ 5892,  2104],\n",
       "        [ 3690,  1854],\n",
       "        [   50,   600],\n",
       "        [  148, 11433]], device='cuda:5')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~ismember(test_edges_false, edges_all)\n",
    "assert ~ismember(val_edges_false, edges_all)\n",
    "assert ~ismember(val_edges, train_edges)\n",
    "assert ~ismember(test_edges, train_edges)\n",
    "assert ~ismember(val_edges, test_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = adj_time_list_t[1].to(device).to_dense()\n",
    "prev = adj_time_list_t[0].to(device).to_dense()\n",
    "edges_pos = torch.nonzero((cur - prev) > 0)\n",
    "num_false = int(edges_pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_pos = np.transpose(np.asarray(np.nonzero((cur - prev)>0)))\n",
    "num_false = int(edges_pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = adj_new.coalesce().indices()\n",
    "values = adj_new.coalesce().values()\n",
    "coordinates = coords[:, torch.where(values > 0)[0]]\n",
    "\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves train_edges adjacency list\n",
    "outs = mask_edges_det_t(adj_time_list)\n",
    "train_edges_l = outs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# masking edges\n",
    "\n",
    "\n",
    "\n",
    "# Get negative and positive edges of adjacency list and returns a bidirectional adjacecny list\n",
    "pos_edges_l, false_edges_l = mask_edges_prd(adj_time_list)\n",
    "\n",
    "# Get negative and positive edges that are newly generated (i has no edge but i+1 has one)\n",
    "pos_edges_l_n, false_edges_l_n = mask_edges_prd_new(adj_time_list)\n",
    "\n",
    "\n",
    "# creating edge list\n",
    "\n",
    "edge_idx_list = []\n",
    "\n",
    "for i in range(len(train_edges_l)):\n",
    "    edge_idx_list.append(torch.tensor(np.transpose(train_edges_l[i]), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "h_dim = 32\n",
    "z_dim = 16\n",
    "n_layers =  1\n",
    "clip = 10\n",
    "learning_rate = 1e-2\n",
    "seq_len = len(train_edges_l)\n",
    "num_nodes = adj_time_list[seq_len-1].shape[0]\n",
    "x_dim = num_nodes\n",
    "eps = 1e-10\n",
    "conv_type='GCN'\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "\n",
    "# creating input tensors per sequence length\n",
    "\n",
    "x_in_list = []\n",
    "\n",
    "x_temp = torch.eye(num_nodes)\n",
    "x_temp = x_temp.expand(seq_len, num_nodes, num_nodes)\n",
    "x_in = Variable(x_temp).to(device)\n",
    "\n",
    "\n",
    "# building model\n",
    "\n",
    "model = VGRNN(x_dim, h_dim, z_dim, n_layers, eps, conv=conv_type, bias=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "seq_start = 0\n",
    "seq_end = seq_len - 3\n",
    "tst_after = 0\n",
    "\n",
    "for k in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    start_time = time.time()\n",
    "    kld_loss, nll_loss, _, _, hidden_st = model(x_in[seq_start:seq_end]\n",
    "                                                , edge_idx_list[seq_start:seq_end]\n",
    "                                                , adj_time_list[seq_start:seq_end])\n",
    "    loss = kld_loss + nll_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "    \n",
    "    if k>tst_after:\n",
    "        _, _, enc_means, pri_means, _ = model(x_in[seq_end:seq_len]\n",
    "                                              , edge_idx_list[seq_end:seq_len]\n",
    "                                              , adj_time_list[seq_end:seq_len]\n",
    "                                              , hidden_st)\n",
    "        \n",
    "        auc_scores_prd, ap_scores_prd = get_roc_scores(pos_edges_l[seq_end:seq_len]\n",
    "                                                        , false_edges_l[seq_end:seq_len]\n",
    "                                                        , adj_time_list[seq_end:seq_len]\n",
    "                                                        , pri_means)\n",
    "        \n",
    "        auc_scores_prd_new, ap_scores_prd_new = get_roc_scores(pos_edges_l_n[seq_end:seq_len]\n",
    "                                                                , false_edges_l_n[seq_end:seq_len]\n",
    "                                                                , adj_time_list[seq_end:seq_len]\n",
    "                                                                , pri_means)\n",
    "        \n",
    "    \n",
    "    print('epoch: ', k)\n",
    "    print('kld_loss =', kld_loss.mean().item())\n",
    "    print('nll_loss =', nll_loss.mean().item())\n",
    "    print('loss =', loss.mean().item())\n",
    "    if k>tst_after:\n",
    "        print('----------------------------------')\n",
    "        print('Link Prediction')\n",
    "        print('link_prd_auc_mean', np.mean(np.array(auc_scores_prd)))\n",
    "        print('link_prd_ap_mean', np.mean(np.array(ap_scores_prd)))\n",
    "        print('----------------------------------')\n",
    "        print('New Link Prediction')\n",
    "        print('new_link_prd_auc_mean', np.mean(np.array(auc_scores_prd_new)))\n",
    "        print('new_link_prd_ap_mean', np.mean(np.array(ap_scores_prd_new)))\n",
    "        print('----------------------------------')\n",
    "    print('----------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
